---
title: "AI in Education: Are We Throwing Rocks When We Have Arrows?"
date: "2025-03-13"
tags: [AI, Education, Georgetown, Credentialism]
featured: true
---

> *“The illiterate of the 21st century will not be those who cannot read and write, but those who cannot learn, unlearn, and relearn.”*  
> — **Alvin Toffler**

# AI in Education: Are We Throwing Rocks When We Have Arrows?

Imagine relying exclusively on your smartphone’s GPS. It's fantastic—until the signal drops, leaving you helplessly lost. Without basic map-reading skills, you're paralyzed. A similar scenario occurred in 2024 when OpenAI briefly restricted its moderation API, leaving countless users stranded. This vividly illustrates a critical risk: the danger of fully depending on powerful tools without retaining foundational skills.

As a CS major at Georgetown—a school more known for policy than technology—I’ve observed broader tensions reflected in my education. At the heart of it is a key question:

**What foundational knowledge truly matters today, and who decides?**

## Reevaluating Educational Foundations

We don't require mechanical engineers to forge engines from scratch, nor do we make accountants reinvent double-entry bookkeeping. Yet computer science education often starts with manual memory management and pointers in C++. But who in the modern workforce, besides niche developers, regularly writes C++? Most professionals now utilize languages like Python, JavaScript, or Go—languages that abstract complexity and allow quicker solutions to real-world problems.

While foundational knowledge is vital, universities must periodically reassess what "foundational" truly means rather than stubbornly sticking to outdated practices.

## Credentialism: Degrees as Educational Credit Scores

Perhaps only one in five of my Georgetown classes genuinely sparked curiosity. Employers still value degrees—not because they measure actual skill or creativity—but because they function like credit scores: imperfect yet universally accepted shorthand for reliability. A degree signals you can meet deadlines and follow rules, not necessarily that you possess innovative or valuable skills.

Recently, I wrote an essay passionately arguing for the thoughtful integration of AI into education, earning a C-. My originality was penalized, while my friend—who meticulously refined her essay through extensive office hours to perfectly meet the professor’s specifications—got an A. She was rewarded not for creativity, but conformity.

## Misplaced Scrutiny and Fears about AI

Every transformative technology brings fears. Calculators once raised alarms about losing arithmetic skills. The internet worried us about superficial reading. Today, professors at Georgetown respond similarly toward AI. Some enthusiastically embrace it, recognizing historical patterns where early adopters benefit the most. Others, however, treat AI purely as advanced cheating.

This suspicion turns professors into academic TSA agents, inspecting trivialities like naming conventions or minor stylistic variations, mistaking inconvenience for genuine educational rigor. Such obsessive scrutiny misses opportunities to leverage AI constructively and wastes precious academic resources.

Even professors themselves sometimes spread misinformation. One professor recently picked a random image-generation tool from HuggingFace and searched explicitly for something negative to highlight. He immediately pointed out an image of a white doctor as evidence of AI bias. Yet, when I asked ChatGPT to generate images of doctors, it showed a remarkably diverse group representing multiple races. By selectively ignoring advancements—like bias mitigation in Google Gemini or DALL-E 3—professors risk oversimplifying AI’s current reality and misinforming students.

## Who Should Decide AI Integration?

Currently, Georgetown professors independently decide AI policy for their classrooms. But should an anthropology professor unfamiliar with AI decide how CS students integrate it? Similarly, should a CS professor who hasn't worked professionally since the days of Windows 95 shape policies on modern AI? Neither scenario makes sense. Educational policy around AI requires informed, balanced, and realistic leadership—not arbitrary individual discretion.

## Preparing Students for Real-World Success

A Georgetown student recently dropped out to launch Mercor, an AI-driven company now valued in the billions, generating over $70 million ARR, and becoming one of the fastest-growing startups globally. Did he learn how to build this transformative business from his classes? Absolutely not. He proactively mastered AI on his own—precisely because traditional educational structures didn't offer him what he needed.

This illustrates the central issue: If professors genuinely aim to create value for students, they should actively help students integrate emerging tools like AI into their education. It’s not impossible—sometimes professors and students might even learn together. If your university doesn’t offer this, as a student, it's your responsibility to independently pursue mastery.

## Autonomous AI: The Future Workplace

Soon, autonomous AI coding systems will handle virtually all computer-based tasks. Yet most of my Georgetown peers will graduate to jobs involving eight-hour days behind a screen, performing tasks AI systems are increasingly capable of automating completely.

If students graduate without learning how to productively collaborate with AI, they'll rapidly become obsolete. Denying this reality in education isn’t merely shortsighted—it actively harms students’ prospects.

## The Path Forward: Education’s Real Choice

Universities today face a stark choice: stubbornly hold onto outdated practices—effectively throwing rocks at a target when bows and arrows are already in hand—or thoughtfully adapt to reality, actively preparing students for success.

Professors who truly care about their students’ future value will guide them in responsibly using AI tools, while students themselves must proactively pursue these essential skills, regardless of restrictive policies.

AI isn’t a panacea, but ignoring it entirely guarantees obsolescence. The question now isn’t whether AI should enter education—it's already here—but how effectively we’ll learn to leverage it. To deny this is to deliberately choose the past over meaningful progress.

It's time we stopped throwing rocks when we clearly have arrows.
